{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ce7d6f6c",
      "metadata": {
        "id": "ce7d6f6c"
      },
      "source": [
        "# Recurrent Neural Network (RNN) for Text Classification\n",
        "This notebook demonstrates a basic RNN model using PyTorch to classify IMDB movie reviews as positive or negative."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required PyTorch modules\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n"
      ],
      "metadata": {
        "id": "UjXtxV7uR4HF"
      },
      "id": "UjXtxV7uR4HF",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manually created small dataset with labeled sentiment examples\n",
        "texts = [\n",
        "    \"good movie\",\n",
        "    \"bad acting\",\n",
        "    \"awesome film\",\n",
        "    \"terrible movie\",\n",
        "    \"loved it\",\n",
        "    \"hated it\"\n",
        "]\n",
        "labels = [1, 0, 1, 0, 1, 0]  # 1 = positive, 0 = negative\n"
      ],
      "metadata": {
        "id": "joImHVRER9Or"
      },
      "id": "joImHVRER9Or",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple tokenizer that splits text into lowercase words\n",
        "tokenizer = lambda x: x.lower().split()\n",
        "# Build vocabulary: assign a unique ID to each word\n",
        "vocab = {\"<PAD>\": 0}  # Start with <PAD> for padding\n",
        "for sentence in texts:\n",
        "    for word in tokenizer(sentence):\n",
        "        if word not in vocab:\n",
        "            vocab[word] = len(vocab)"
      ],
      "metadata": {
        "id": "cNLtLR8ZSBme"
      },
      "id": "cNLtLR8ZSBme",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom dataset class for PyTorch\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels):\n",
        "        self.data = [(torch.tensor(label, dtype=torch.float), encode(text)) for text, label in zip(texts, labels)]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "# Custom collate function to pad variable-length sequences\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list = [], []\n",
        "    for label, text in batch:\n",
        "        label_list.append(label)\n",
        "        text_list.append(text)\n",
        "    return pad_sequence(text_list, batch_first=True), torch.tensor(label_list)\n",
        "\n",
        "# DataLoader to create batches from dataset\n",
        "dataset = TextDataset(texts, labels)\n",
        "loader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_batch)\n"
      ],
      "metadata": {
        "id": "SzJn_WtaSF39"
      },
      "id": "SzJn_WtaSF39",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple RNN model with embedding, RNN layer, and a fully connected output layer\n",
        "class SimpleRNN(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)\n",
        "        _, h_n = self.rnn(x)\n",
        "        out = self.fc(h_n.squeeze(0))\n",
        "        return self.sigmoid(out).squeeze()\n"
      ],
      "metadata": {
        "id": "M7vuVmPBSJ-s"
      },
      "id": "M7vuVmPBSJ-s",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x1JEF05bU3oF",
        "outputId": "3e742c37-e714-4e8a-cfc5-92ddcec94acf"
      },
      "id": "x1JEF05bU3oF",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu11 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu11 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.11/dist-packages (2.0.1)\n",
            "Requirement already satisfied: torchvision==0.15.2 in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Requirement already satisfied: torchaudio==2.0.2 in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (4.13.2)\n",
            "Collecting sympy (from torch==2.0.1)\n",
            "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (8.5.0.96)\n",
            "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.1)\n",
            "  Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (10.2.10.91)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (2.14.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (11.7.91)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.0.1) (2.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (2.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision==0.15.2) (11.2.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (80.3.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.45.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1) (4.0.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.11/dist-packages (from triton==2.0.0->torch==2.0.1) (18.1.8)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.0.1) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchvision==0.15.2) (2025.4.26)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.0.1) (1.3.0)\n",
            "Using cached nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu11 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mInstalling collected packages: sympy, nvidia-cublas-cu11\n",
            "\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu11 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~vidia-cublas-cu11 (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Ignoring invalid distribution ~ympy (/usr/local/lib/python3.11/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu11 sympy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QV2gOFQT1_P",
        "outputId": "d4772861-76a8-460b-a912-7c560d4f922f"
      },
      "id": "2QV2gOFQT1_P",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.0.1+cu117\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize model, loss function, and optimizer\n",
        "model = SimpleRNN(len(vocab), embed_dim=10, hidden_dim=16)\n",
        "loss_fn = nn.BCELoss()  # Binary cross entropy loss for binary classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# Training loop over 5 epochs\n",
        "model.train()\n",
        "for epoch in range(5):\n",
        "    for x_batch, y_batch in loader:\n",
        "        optimizer.zero_grad()              # Reset gradients\n",
        "        preds = model(x_batch)             # Forward pass\n",
        "        loss = loss_fn(preds, y_batch)     # Compute loss\n",
        "        loss.backward()                    # Backpropagation\n",
        "        optimizer.step()                    # Update weights\n",
        "    print(f\"Epoch {epoch+1} Loss: {loss.item():.4f}\")   # Print loss for each epoch\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8gLNwsRSMG6",
        "outputId": "659723a7-096b-443d-eb81-2ebb3f9cfb5b"
      },
      "id": "U8gLNwsRSMG6",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Loss: 0.7407\n",
            "Epoch 2 Loss: 0.5476\n",
            "Epoch 3 Loss: 0.5783\n",
            "Epoch 4 Loss: 0.4377\n",
            "Epoch 5 Loss: 0.3722\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The steady decline in loss suggests that the RNN is successfully learning to distinguish between positive and negative sentiment, even with a very small dataset. While the fluctuations (like in epoch 3) are normal due to small batch sizes, the overall trend indicates that the model is training effectively."
      ],
      "metadata": {
        "id": "YwcHJyoHav2M"
      },
      "id": "YwcHJyoHav2M"
    },
    {
      "cell_type": "markdown",
      "id": "02083a49",
      "metadata": {
        "id": "02083a49"
      },
      "source": [
        "You can expand this notebook by adding full training loops, evaluation metrics, and visualizations of training/validation performance."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5cd97af",
   "metadata": {},
   "source": [
    "**Name:** Bhavyasai Chinchugalla\n",
    "\n",
    "High Performance Computing - 07\n",
    "\n",
    "**Week 07 - Spark Application**\n",
    "\n",
    "**Banner ID:** 001321696"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b38348",
   "metadata": {},
   "source": [
    "### Loads Files Into Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218650f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%fs ls /FileStore/tables/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19d4d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.fs.cp(\n",
    "    \"dbfs:/FileStore/tables/PGYR2023_P01302025_01212025-5.zip\",\n",
    "    \"file:/databricks/driver/data.zip\",\n",
    "    True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d9938b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "\n",
    "zip_path = \"/databricks/driver/data.zip\"\n",
    "extract_path = \"/dbfs/FileStore/tables/unzipped/\"\n",
    "\n",
    "try:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        print(\"Contents of ZIP:\")\n",
    "        print(zip_ref.namelist())\n",
    "        zip_ref.extractall(extract_path)\n",
    "    print(\"✅ Unzipping complete.\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Error while unzipping:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c4c197",
   "metadata": {},
   "outputs": [],
   "source": [
    "%fs ls /FileStore/tables/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8745bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.fs.cp(\"dbfs:/FileStore/tables/PGYR2023_P01302025_01212025-5.zip\", \"file:/tmp/data.zip\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa73c5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh\n",
    "unzip -o /tmp/data.zip -d /tmp/unzipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8aaa319",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh\n",
    "cp /tmp/unzipped/OP_DTL_GNRL_PGYR2023_P01302025_01212025.csv /dbfs/FileStore/tables/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61069f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh\n",
    "ls -lh /tmp/unzipped/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f4d05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sh\n",
    "echo \"Creating sample_general.csv...\"\n",
    "head -n 10001 /tmp/unzipped/OP_DTL_GNRL_PGYR2023_P01302025_01212025.csv > /dbfs/FileStore/tables/sample_general.csv\n",
    "echo \"Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca6f9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\"file:/tmp/unzipped/OP_DTL_GNRL_PGYR2023_P01302025_01212025.csv\").limit(10000)\n",
    "df_sample.cache()\n",
    "display(df_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5136f4d6",
   "metadata": {},
   "source": [
    "### Load and Extract Covered Recipient File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d9b61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbutils.fs.cp(\n",
    "    \"dbfs:/FileStore/tables/PHPRFL_P01302025_01212025.zip\",\n",
    "    \"file:/databricks/driver/recipient.zip\",\n",
    "    True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e106aae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile, os\n",
    "\n",
    "zip_path = \"/databricks/driver/recipient.zip\"\n",
    "extract_path_local = \"/databricks/driver/recipient_unzipped\"\n",
    "extract_path_dbfs = \"/dbfs/FileStore/tables/recipient_unzipped\"\n",
    "os.makedirs(extract_path_local, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.printdir()\n",
    "        zip_ref.extractall(extract_path_local)\n",
    "        print(\"\\n✅ Extraction to local driver complete.\")\n",
    "    os.makedirs(extract_path_dbfs, exist_ok=True)\n",
    "    for file_name in os.listdir(extract_path_local):\n",
    "        src = os.path.join(extract_path_local, file_name)\n",
    "        dst = os.path.join(extract_path_dbfs, file_name)\n",
    "        dbutils.fs.cp(f\"file:{src}\", f\"dbfs:/FileStore/tables/recipient_unzipped/{file_name}\", True)\n",
    "        print(f\"✅ Copied: {file_name}\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Error while unzipping or copying:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40770424",
   "metadata": {},
   "outputs": [],
   "source": [
    "%fs ls /FileStore/tables/recipient_unzipped/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b24ee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipient_df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(\n",
    "    \"dbfs:/FileStore/tables/recipient_unzipped/OP_CVRD_RCPNT_PRFL_SPLMTL_P01302025_01212025.csv\")\n",
    "display(recipient_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f338816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_df = df_sample.join(\n",
    "    recipient_df,\n",
    "    on=\"Covered_Recipient_Profile_ID\",\n",
    "    how=\"inner\"\n",
    ")\n",
    "joined_df.cache()\n",
    "display(joined_df.limit(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cc318c",
   "metadata": {},
   "source": [
    "### 1. What is the Nature of Payments > $1,000 ordered by count?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2732389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count as _count\n",
    "\n",
    "analysis_1 = (\n",
    "    joined_df.filter(col(\"Total_Amount_of_Payment_USDollars\") > 1000)\n",
    "    .groupBy(\"Nature_of_Payment_or_Transfer_of_Value\")\n",
    "    .agg(_count(\"*\").alias(\"count\"))\n",
    "    .orderBy(col(\"count\").desc())\n",
    ")\n",
    "display(analysis_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3333bcf",
   "metadata": {},
   "source": [
    "### 2. Top 10 Nature of Payments by count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5883ceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count as _count\n",
    "\n",
    "analysis_2 = (\n",
    "    joined_df.groupBy(\"Nature_of_Payment_or_Transfer_of_Value\")\n",
    "    .agg(_count(\"*\").alias(\"count\"))\n",
    "    .orderBy(col(\"count\").desc())\n",
    "    .limit(10)\n",
    ")\n",
    "display(analysis_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16473e2",
   "metadata": {},
   "source": [
    "### 3. Top 10 Nature of Payments by total amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1d8c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum as _sum, col\n",
    "\n",
    "analysis_3 = (\n",
    "    joined_df.groupBy(\"Nature_of_Payment_or_Transfer_of_Value\")\n",
    "    .agg(_sum(\"Total_Amount_of_Payment_USDollars\").alias(\"total_amount\"))\n",
    "    .orderBy(col(\"total_amount\").desc())\n",
    "    .limit(10)\n",
    ")\n",
    "display(analysis_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c478d28",
   "metadata": {},
   "source": [
    "### 4. Top 10 Physician Specialties by Total Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf486c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_4 = (\n",
    "    joined_df.groupBy(\"Covered_Recipient_Specialty_1\")\n",
    "    .agg(_sum(\"Total_Amount_of_Payment_USDollars\").alias(\"total_amount\"))\n",
    "    .orderBy(col(\"total_amount\").desc())\n",
    "    .limit(10)\n",
    ")\n",
    "display(analysis_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a49c39",
   "metadata": {},
   "source": [
    "### 5. Top 10 Physicians by Total Amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6097790",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum as _sum, col, concat_ws\n",
    "\n",
    "joined_df = joined_df.withColumn(\n",
    "    \"Physician_Name\",\n",
    "    concat_ws(\" \", col(\"Covered_Recipient_First_Name\"), col(\"Covered_Recipient_Last_Name\"))\n",
    ")\n",
    "\n",
    "analysis_5 = (\n",
    "    joined_df.groupBy(\"Physician_Name\")\n",
    "    .agg(_sum(\"Total_Amount_of_Payment_USDollars\").alias(\"total_amount\"))\n",
    "    .orderBy(col(\"total_amount\").desc())\n",
    "    .limit(10)\n",
    ")\n",
    "display(analysis_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441b92cb",
   "metadata": {},
   "source": [
    "## Summary\n",
    "This notebook explores the 2023 CMS Open Payments dataset, performing five key analyses using PySpark:\n",
    "- Nature of payments > $1,000\n",
    "- Top 10 payment types by count and amount\n",
    "- Top specialties and physicians by amount\n",
    "The analysis offers insight into how medical professionals interact with industry payments.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

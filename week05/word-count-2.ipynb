{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.bag as db\n",
    "import string\n",
    "import csv\n",
    "import graphviz\n",
    "import itertools \n",
    "import collections\n",
    "\n",
    "def create_word_count_dictionary(text) :\n",
    "    \"\"\"Creates a word/count dictionary for all of the words in a set of text.\n",
    "    >>> create_word_count_dictionary(\"Hello world\")\n",
    "    {'Hello': 1, 'world': 1}\n",
    "\n",
    "    \"\"\"\n",
    "    dict = {}\n",
    "    for word in text.split() :\n",
    "        if word in dict.keys() :\n",
    "            dict[word] = dict[word] + 1\n",
    "        else :\n",
    "            dict[word] = 1\n",
    "    return dict\n",
    "\n",
    "def remove_punctuation(text) :\n",
    "    \"\"\"Removes punctuation from text.\n",
    "    >>> remove_punctuation(\"Hello, world\")\n",
    "    'Hello world'\n",
    "\n",
    "    \"\"\"\n",
    "    return ''.join(filter(lambda x: x not in string.punctuation, text))\n",
    "\n",
    "stop_words = [\"a\", \"an\", \"the\", \"and\", \"but\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\", \"too\", \"very\", \"can\", \"will\", \"just\"]\n",
    "\n",
    "def remove_stop_words(text) :\n",
    "    \"\"\"Removes stop words from text.\n",
    "    >>> remove_stop_words(\"The quick brown fox jumps over the lazy dog.\")\n",
    "    'quick brown fox jumps lazy dog.'\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    return ' '.join(filter(lambda x: x.lower() not in stop_words, text.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_reason(csvfile) :\n",
    "    \"\"\"Extracts the reason text minus punctuation from csv files.\n",
    "    >>> extract_reason(open(\"test.csv\", newline=''))\n",
    "    '  Undeclared Nnitrosodiethylamine NDEA Undeclared colloidal silver and lack of sterility assurance'\n",
    "\n",
    "    \"\"\"\n",
    "    reader = csv.DictReader(csvfile, delimiter=\"|\")\n",
    "    clean_text = \" \"\n",
    "    for row in reader:    \n",
    "        clean_text = \" \".join((clean_text, remove_punctuation(row[\"Reason\"])))\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_year(year) :\n",
    "    filename = \"recalls{}.csv\".format(year)\n",
    "    csvfile = open(filename, newline='')\n",
    "    clean_text = extract_reason(csvfile)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_dictionaries(dict1, dict2) :\n",
    "    \"\"\"Adds two dictionaries together.\n",
    "    >>> add_dictionaries({\"a\": 1, \"b\": 2}, {\"a\":3, \"c\":3})\n",
    "    defaultdict(<class 'int'>, {'a': 4, 'b': 2, 'c': 3})\n",
    "\n",
    "    \"\"\"\n",
    "    c = collections.defaultdict(int)\n",
    " \n",
    "    # iterating key, val with chain()\n",
    "    for key, val in itertools.chain(dict1.items(), dict2.items()):\n",
    "        c[key] += val\n",
    "    return c\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = db.from_sequence([2018, 2019, 2020, 2021, 2022, 2023, 2024]) \\\n",
    "    .map(load_from_year)    \\\n",
    "    .map(remove_stop_words) \\\n",
    "    .map(create_word_count_dictionary) \\\n",
    "    .fold(add_dictionaries)\n",
    "bag.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = bag.compute()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_based_rev = {k: v for k, v in sorted(result[0].items(), key=lambda item: item[1], reverse=True)}\n",
    "print(val_based_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = db.from_sequence([2018, 2019, 2020, 2021, 2022, 2023, 2024]) \\\n",
    "    .map(load_from_year)    \\\n",
    "    .map(remove_stop_words) \\\n",
    "    .str.split()            \\\n",
    "    .flatten()              \\\n",
    "    .frequencies()\n",
    "\n",
    "bag.visualize()\n",
    "\n",
    "result = bag.compute()\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
